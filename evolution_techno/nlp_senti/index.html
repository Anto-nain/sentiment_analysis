<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-evolution_techno/nlp_senti" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Les LLMs : une nouvelle façon d&#x27;analyser les sentiments | My Site</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/sentiment_analysis/img/logo.png"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/sentiment_analysis/img/logo.png"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/sentiment_analysis/evolution_techno/nlp_senti"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Les LLMs : une nouvelle façon d&#x27;analyser les sentiments | My Site"><meta data-rh="true" name="description" content="Depuis 2018, les LLMs (Large Language Models) ont révolutionné le domaine du traitement automatique du langage naturel (NLP). Ces modèles, basés sur des réseaux de neurones, sont capables de générer ou comprendre du texte de manière autonome, en fonction d&#x27;une tâche donnée. Ces nouvelles structures de traitement de texte ne se contentent plus de reconnaître des mots comme le feraient les dictionnaires, mais sont capables de comprendre le sens des phrases à des niveaux de profondeur parfois plus importants que les humains."><meta data-rh="true" property="og:description" content="Depuis 2018, les LLMs (Large Language Models) ont révolutionné le domaine du traitement automatique du langage naturel (NLP). Ces modèles, basés sur des réseaux de neurones, sont capables de générer ou comprendre du texte de manière autonome, en fonction d&#x27;une tâche donnée. Ces nouvelles structures de traitement de texte ne se contentent plus de reconnaître des mots comme le feraient les dictionnaires, mais sont capables de comprendre le sens des phrases à des niveaux de profondeur parfois plus importants que les humains."><link data-rh="true" rel="icon" href="/sentiment_analysis/img/logo.png"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/sentiment_analysis/evolution_techno/nlp_senti"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/sentiment_analysis/evolution_techno/nlp_senti" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/sentiment_analysis/evolution_techno/nlp_senti" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/sentiment_analysis/blog/rss.xml" title="My Site RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/sentiment_analysis/blog/atom.xml" title="My Site Atom Feed"><link rel="stylesheet" href="/sentiment_analysis/assets/css/styles.e095cc78.css">
<script src="/sentiment_analysis/assets/js/runtime~main.64d3f58d.js" defer="defer"></script>
<script src="/sentiment_analysis/assets/js/main.5cdf7186.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/sentiment_analysis/img/logo.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/sentiment_analysis/"><div class="navbar__logo"><img src="/sentiment_analysis/img/logo.png" alt="ECL" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/sentiment_analysis/img/logo.png" alt="ECL" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">L&#x27;analyse de Sentiment dans le Secteur Financier</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/sentiment_analysis/"> </a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/Anto-nain/sentiment_analysis" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/sentiment_analysis/">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/sentiment_analysis/contexte">Contexte</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/sentiment_analysis/evolution_techno/dict_senti">Évolutions des technologies</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/sentiment_analysis/evolution_techno/dict_senti">Les premières technologies</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/sentiment_analysis/evolution_techno/nlp_senti">Les LLMs</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/sentiment_analysis/next">Et après ?</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/sentiment_analysis/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Évolutions des technologies</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Les LLMs</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Les LLMs : une nouvelle façon d&#x27;analyser les sentiments</h1></header>
<p>Depuis 2018, les LLMs (Large Language Models) ont révolutionné le domaine du traitement automatique du langage naturel (NLP). Ces modèles, basés sur des réseaux de neurones, sont capables de générer ou comprendre du texte de manière autonome, en fonction d&#x27;une tâche donnée. Ces nouvelles structures de traitement de texte ne se contentent plus de reconnaître des mots comme le feraient les dictionnaires, mais sont capables de comprendre le sens des phrases à des niveaux de profondeur parfois plus importants que les humains.</p>
<p>Il s&#x27;agira dans cette section de comprendre comment ces modèles ont permis une avancée majeure dans le domaine de l&#x27;analyse de sentiment, et comment ils ont des applications concrètes dans le milieu financier.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="le-finetuning-des-llms-pour-le-rendement-anticipé-dactions">Le finetuning des LLMs pour le rendement anticipé d&#x27;actions<a href="#le-finetuning-des-llms-pour-le-rendement-anticipé-dactions" class="hash-link" aria-label="Direct link to Le finetuning des LLMs pour le rendement anticipé d&#x27;actions" title="Direct link to Le finetuning des LLMs pour le rendement anticipé d&#x27;actions">​</a></h2>
<p>Les premiers LLMs sont apparus en 2018, avec le modèle <em>GPT-1</em> (Generative Pre-trained Transformer). Peu après est arrivé le premier modèle open source de google : <em>BERT</em>.</p>
<p><em>BERT</em> pour <em>Bidirectional Encoder Representations from Transformers</em> se distingue du modèle <em>GPT</em> par sa capacité à prendre le contexte précédent et suivant d&#x27;un mot, afin de mieux en comprendre le sens. Dans le papier de recherche de ce modèle, les auteurs présentent une structure de réseau de neurone de type <em>transformer</em> <a href="#sources">[1]</a>. La structure de ce réseau est basée sur un assemblage de couches d&#x27;encodeurs de transformers qui possèdent un mécanisme de <em>multi-head self-attention</em> et de <em>feed-forward neural network</em>. C&#x27;est ce qui permet à <em>BERT</em> de réaliser l&#x27;<em>embedding</em> des inputs textuels.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Embedding</div><div class="admonitionContent_BuS1"><p>L&#x27;<em>embedding</em> est une technique de traitement de texte qui consiste à représenter les mots ou phrases sous forme de vecteurs. L&#x27;objectif est de conserver les relations sémantiques entre ces derniers, et de les représenter dans un espace vectoriel. Ainsi, on peut réaliser des opérations mathématiques sur ces vecteurs pour obtenir des informations sur les mots ou phrases qu&#x27;ils représentent. Par exemple :</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>e</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy="false">(</mo><mi mathvariant="normal">&quot;</mi><mi>r</mi><mi>o</mi><mi>i</mi><mi mathvariant="normal">&quot;</mi><mo stretchy="false">)</mo><mo>−</mo><mi>e</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy="false">(</mo><mi mathvariant="normal">&quot;</mi><mi>h</mi><mi>o</mi><mi>m</mi><mi>m</mi><mi>e</mi><mi mathvariant="normal">&quot;</mi><mo stretchy="false">)</mo><mo>+</mo><mi>e</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy="false">(</mo><mi mathvariant="normal">&quot;</mi><mi>f</mi><mi>e</mi><mi>m</mi><mi>m</mi><mi>e</mi><mi mathvariant="normal">&quot;</mi><mo stretchy="false">)</mo><mo>≈</mo><mi>e</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy="false">(</mo><mi mathvariant="normal">&quot;</mi><mi>r</mi><mi>e</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi mathvariant="normal">&quot;</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">embedding(&quot;roi&quot;) - embedding(&quot;homme&quot;) + embedding(&quot;femme&quot;) \approx embedding(&quot;reine&quot;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">e</span><span class="mord mathnormal">dd</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord">&quot;</span><span class="mord mathnormal">ro</span><span class="mord mathnormal">i</span><span class="mord">&quot;</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">e</span><span class="mord mathnormal">dd</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord">&quot;</span><span class="mord mathnormal">h</span><span class="mord mathnormal">o</span><span class="mord mathnormal">mm</span><span class="mord mathnormal">e</span><span class="mord">&quot;</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">e</span><span class="mord mathnormal">dd</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord">&quot;</span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mord mathnormal">e</span><span class="mord mathnormal">mm</span><span class="mord mathnormal">e</span><span class="mord">&quot;</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">e</span><span class="mord mathnormal">dd</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord">&quot;</span><span class="mord mathnormal">re</span><span class="mord mathnormal">in</span><span class="mord mathnormal">e</span><span class="mord">&quot;</span><span class="mclose">)</span></span></span></span></span></div></div>
<p>À l&#x27;inverse des techniques de <em>word-embedding</em> classiques telles que <em>Word2Vec</em> ou <em>GloVe</em>, <em>BERT</em> est capable de prendre en compte le contexte global du texte pour réaliser l&#x27;<em>embedding</em> des mots. C&#x27;est ce qui lui donne une compréhension plus fine du sens des mots et des phrases. <em>BERT</em> va donc réaliser 3 <em>embeddings</em> différents pour chaque mot (voir <a href="#bert-embedding">Figure 1</a>) :</p>
<ul>
<li>l&#x27;embedding du mot lui-même</li>
<li>l&#x27;embedding de la position du mot</li>
<li>l&#x27;embedding de la position de la phrase dans le texte</li>
</ul>
<p>Ce sont ces 2 derniers <em>embeddings</em> qui permettent à <em>BERT</em> de comprendre le contexte global du texte et de détecter ses structures <em>questions/réponses</em>.</p>
<div id="bert-embedding"><p><img decoding="async" loading="lazy" alt="BERT embedding" src="/sentiment_analysis/assets/images/bert_embedding-8759513246e46f8e80f5930ff68fcab5.png" width="1633" height="508" class="img_ev3q"></p></div>
<figcaption style="text-align:center"><em>Figure 1 : Embedding des inputs dans le modèle BERT <a href="#ref1">[1]</a></em></figcaption>
<p>L&#x27;entrainement d&#x27;un modèle de <em>LLM</em> comme <em>BERT</em> se fait en deux étapes :</p>
<p><strong>1/ Pré-entrainement</strong></p>
<p>Le modèle apprend à réaliser les 3 <em>embeddings</em> des mots d&#x27;un texte. Pour cela, il est entraîné sur deux tâches principales :</p>
<ol>
<li><em>Masked Language Model</em> : 15% des mots du texte sont masqués, et le modèle doit apprendre à les retrouver en fonction du contexte.</li>
<li><em>Next Sentence Prediction</em> : on donne deux phrases, A et B au modèle tel que B est la phrase suivante de A dans 50% des cas. Le modèle doit alors apprendre à déterminer si B est bien la phrase suivante de A.</li>
</ol>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Objectif du pré-entrainement</div><div class="admonitionContent_BuS1"><p>Grâce au pré-entrainement, <em>BERT</em> apprend deux notions fondamentales pour sa compréhension du langage : La cohérence <strong>contextuelle</strong> et <strong>sémantique</strong> du langage.</p></div></div>
<p><strong>2/ Fine-tuning</strong></p>
<p>Une fois pré-entrainé, on peut ré-entrainer <em>BERT</em> pour qu&#x27;il réalise une tâche bien précise. Ayant au préalable acquis un compréhension du langage, il peut maintenant apprendre à réaliser une tâche plus complexe sur les données textuelles. On peut notamment lui apprendre à générer du texte pour répondre à une question ou à réaliser une classification de texte ; pour détecter des spams par exemple.</p>
<p>Dans le contexte de l&#x27;analyse de sentiment, on peut utiliser le modèle pré-entrainé de <em>BERT</em> pour réaliser une classification des textes en fonction de leur sentiment. C&#x27;est notamment ce qu&#x27;on réalisé l&#x27;équipe <em>Systematic Equity</em> chez <em>RAM AI</em> <a href="#sources">[2]</a>.</p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>L&#x27;importance de la donnée</div><div class="admonitionContent_BuS1"><p>Le pré-entrainement d&#x27;un <em>LLM</em> comme <em>BERT</em> nécessite une grande quantité de données textuelles de bonne qualité. Pour ce faire, on utilise souvent des corpus de textes libres, comme <em>Wikipedia</em> ou <em>Common Crawl</em>. Cependant, ces données ne sont pas toujours adaptées à la tâche finale que l&#x27;on souhaite réaliser. Dans le cadre financier, de nombreux termes techniques ou spécifiques peuvent ne pas être présents dans ces corpus, ou tout du moins pas en suffisamment grande quantité pour que le modèle comprenne pleinement leur sens.</p></div></div>
<p>Dans ce contexte financier d&#x27;analyse de sentiment, l&#x27;équipe de <em>RAM AI</em> a donc d&#x27;abord réalisé un fine-tuning de <em>BERT</em> sur un corpus de données financières avec des étiquettes de sentiments. Ce modèle de langage renommé <strong>FinBERT</strong> est donc maintenant capable de comprendre le langage en général et tout particulièrement le langage financier et les sentiments associés à ce dernier (voir <a href="#finbert">Figure 2</a>).</p>
<div id="finbert"><p><img decoding="async" loading="lazy" alt="FinBERT" src="/sentiment_analysis/assets/images/finbert-7401d575fe89c52e70feee7701045d65.png" width="1212" height="457" class="img_ev3q"></p></div>
<figcaption style="text-align:center"><em>Figure 2 : Fine-tuning de BERT pour l&#x27;analyse de sentiment financier <a href="#sources">[2]</a></em></figcaption>
<p>À partir de <strong>FinBERT</strong>, l&#x27;équipe de <em>RAM AI</em> a aussi mis au point une version <em>Ditangled</em> pour décorréler les mécanismes du modèle <em>BERT</em> (notamment sur la dimension la dimension des embeddings et sur le mécanisme d&#x27;attention) : <strong>FinDeBERTa</strong>. D&#x27;un point de vue des performances, ils ont utilisés ces modèles pour prédire le sentiment des marchés financiers sur des données de nouvelles financières. Leur objectif était de simuler un investissement dans des actions du marché afin d&#x27;améliorer leur <em>rendement</em> (défini sur la page précédente). En comparant les performances de <strong>FinBERT</strong> et <strong>FinDeBERTa</strong> avec <strong>FinVADER</strong> (un dictionnaire de sentiment axé sur la finance vu sur la page précédente), ils ont obtenus les résultats de la <a href="#finbert-perf">Figure 3</a>.</p>
<div id="finbert-perf"><p><img decoding="async" loading="lazy" alt="Performances de FinBERT et FinDeBERTa" src="/sentiment_analysis/assets/images/bert_perf-842002ccb70ac8cac3e7ae6a33d701c0.png" width="963" height="712" class="img_ev3q"></p></div>
<figcaption style="text-align:center"><em>Figure 3 : Performances de FinBERT et FinDeBERTa comparées à FinVADER <a href="#sources">[2]</a></em></figcaption>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Ce qu&#x27;il faut retenir</div><div class="admonitionContent_BuS1"><p>Dans le cadre d&#x27;une simulation d&#x27;investissement sur le marché des actions, les modèles de <em>LLM</em> affinés pour l&#x27;analyse de sentiment financier produisent des résultats significativement meilleurs que les dictionnaires de sentiment classiques. Cela est du à leur compréhension plus fine et entière du language financier.
En moyenne, on peut noter une amélioration 3 à 4 fois supérieure à l&#x27;utilisation d&#x27;un dictionnaire de sentiment (même spécifique à la finance).</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="les-méta-modèles">Les Méta-modèles<a href="#les-méta-modèles" class="hash-link" aria-label="Direct link to Les Méta-modèles" title="Direct link to Les Méta-modèles">​</a></h2>
<p>Une des avancée les plus surprenante concernant l&#x27;utilisation des <em>LLMs</em> est leur transformation en agent conversationnel. Ces nouveaux systèmes intelligents sont au coeur de la recherche en IA pour l&#x27;analyse de sentiment, notamment dans le domaine financier.</p>
<p>Lorsque l&#x27;on travaille dans le milieu financier, ou plus généralement dans un domaine critique, il est important de pouvoir détailler rigouresement le cheminement d&#x27;un pensée. Les IAs génératives, comme <em>FinBERT</em> de la section précédent ne le font naturellement pas. C&#x27;est pourquoi il est souvent nécessaire de leur apprendre à raisonner de façon logique et humaine. Pour ce faire, il existe de nombreuses méthodes, qui permettent en plus d&#x27;améliorer la précision et la qualité des réponses de ces agents, dont notamment les <em>Chain of Thought</em>, <em>Tree of Thought</em> ou encore des mécanismes d&#x27;<em>auto-vérification de la cohérence</em>.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span><em>Chain of Thought</em> et <em>Tree of Thought</em></div><div class="admonitionContent_BuS1"><p>Les <em>Chain of Thought (CoT)</em> et <em>Tree of Thoughts (ToT)</em> sont des techniques d’amélioration du raisonnement pour les modèles de langage. <em>CoT</em> guide le modèle à décomposer une tâche en plusieurs étapes explicites, améliorant ainsi la cohérence des réponses. <em>ToT</em>, quant à lui, étend cette idée en explorant plusieurs chemins de raisonnement sous forme d’un arbre, permettant au modèle d’évaluer différentes solutions avant de choisir la meilleure. Alors que <em>CoT</em> suit un raisonnement linéaire, <em>ToT</em> est plus puissant pour les tâches complexes nécessitant une exploration et une prise de décision optimales.</p></div></div>
<p>Ces modèles, performants pour analyser les sentiments dans de nombreux domaines, ont pourtant certaines limitations dans leur réflexion. Ils ne sont en effet, pas capables de proposer des raisonnements intellectuels spontanés ; c&#x27;est-&amp;-dire autres que dans le cadre qui leur a été appris (<em>CoT</em>, <em>ToT</em>, ...).Dans l&#x27;article <em>Designing Heterogeneous LLM Agents for Financial Sentiment Analysis</em> <a href="#sources">[3]</a> Franck Xing dépeint l&#x27;utilisation de différents méta-modèles pour palier ces limitations.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Les méta-modèles</div><div class="admonitionContent_BuS1"><p>Un méta-modèle est une structure conceptuelle qui définit les règles et les relations régissant un ensemble de modèles spécifiques. Il sert de cadre général permettant d’organiser, d’interconnecter et d’adapter différents modèles selon les besoins d’un domaine donné. Dans le contexte des agents conversationnels, un méta-modèle peut orchestrer plusieurs sous-modèles spécialisés (compréhension, génération, mémoire contextuelle, raisonnement, etc.), afin de produire agent plus flexible, capable de mieux structurer ses réponses et d’adapter son comportement aux interactions.</p></div></div>
<p>Dans cet article, Franck Xing propose un méta-modèle inspiré de la théorie de l&#x27;esprit de Marvin Minsky.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span><em>The Society of Mind - Marvin Minsky</em></div><div class="admonitionContent_BuS1"><p>Dans son livre intitulé <em>The Society of Mind</em> <a href="#sources">[4]</a>, Marvin Minsky présente une approche théorique qui propose que l&#x27;intelligence humaine émerge de l&#x27;interaction de nombreux agents cognitifs ou modules spécialisés dans le cerveau.</p></div></div>
<p>En suivant cette théorie, Franck Xing propose un méta-modèle d&#x27;agents conversationnels dont les conversations cherchent à améliorer la qualité de la réflexion de l&#x27;agent. Ce modèle, le <strong>HAD</strong> pour <strong>Heterogeneous multi-Angent Discussion</strong>, est composé de 7 types d&#x27;agents ; 5 d&#x27;entre-eux sont des agents linguistiques et 2 sont des agents financiers :</p>
<ul>
<li><strong>Agents linguistiques</strong>
<ul>
<li><strong>A1 - agent mood</strong> : détecte les moods irréalistes, c&#x27;est-à-dire des expressions qui indiquent des conditions hypothétiques ou improbables. Par exemple : &quot;Si les conditions économiques s&#x27;améliorent alors...&quot;</li>
<li><strong>A2 - agent rhétorique</strong> : identifie les rhétoriques, comme le sarcasme ou les assertions négatives.</li>
<li><strong>A3 - agent dépendance</strong> : se concentre sur le sentiment de l&#x27;orateur, et non sur celui d&#x27;un tiers. Par exemple : &quot;Nous sommes optimistes&quot; (focus sur l&#x27;orateur) et &quot;Les analystes sont optimistes&quot; (focus sur un tiers).</li>
<li><strong>A4 - agent aspect</strong> : se concentre sur le sujet principal (par exemple, une action ou un produit) et non sur des aspects secondaires.</li>
<li><strong>A5 - agent référence</strong> : détecte les références temporelles, les prix et autres faits non exprimés.</li>
</ul>
</li>
<li><strong>Agents financiers</strong>
<ul>
<li><strong>A6 - agent institutionnel</strong> : analyse le texte du point de vue d&#x27;un investisseur institutionnel, en se concentrant sur les effets fondamentaux à long terme</li>
<li><strong>A7 - agent individuel</strong> : analyse le texte du point de vue d&#x27;un investisseur individuel, en se concentrant sur les changements de prix et les indicateurs techniques.</li>
</ul>
</li>
</ul>
<p>Cette structure de méta-modèle avec différents types d&#x27;agents tous focus sur des aspects différents de l&#x27;analyse du texte se distingue par sa complexité des autres méta-modèles existants. Cette structure plus complexe mimique en effet plus fidèlement le fonctionnement du cerveau humain, ou à fortiori, d&#x27;un analyste financier ou de son équipe : chacun se concentrant sur un aspect particulier de l&#x27;analyse.</p>
<div id="had"><p><img decoding="async" loading="lazy" alt="HAD" src="/sentiment_analysis/assets/images/had_comp-3c0e12a37a6db021b25581144c7238fb.png" width="1567" height="727" class="img_ev3q"></p></div>
<figcaption style="text-align:center"><em>Figure 4 : Différentes structures de méta-modèles en multi-agent, (a) <strong>homogeneous multi-agent debate</strong>, (b) <strong>multi-role multi-agent negotiation</strong>, (c) <strong>heterogeneous multi-agent discussion (HAD)</strong> <a href="#source">[3]</a></em></figcaption>
<p>Dans la <a href="#had">Figure 4</a>, on peut voir deux autres structures de méta-modèles plus simples que le <strong>HAD</strong> (c) :</p>
<ul>
<li>(a) <strong>Homogeneous multi-agent debate</strong> : cette structure présentée par les recherches de Yilun DU et al. <a href="#sources">[5]</a> propose de lier des nombreux agents identiques au sein d&#x27;un même modèle. Toujours en s&#x27;appuyant sur la théorie de Minsky <a href="#sources">[4]</a>, ils ont fait débatre leurs agents pour analyser sentimentalement un texte.</li>
<li>(b) <strong>Multi-role multi-agent negotiation</strong> : cette structure présentée par les recherches de Xiaofei SUN et al. <a href="#sources">[6]</a>, fait intervenir des agents dans une négotiation chacun ayant un rôle différent. Cette structure, plus proche du <strong>HAD</strong>, se distingue par le fait que les agents ont le même type d&#x27;analyse ; seul leur rôle dans le débat diffère (négociateur, observateur, ...). Suite aux négociations, le consensus atteint est sytématiquement remis en question. Cela mimique le déroulé d&#x27;un vrai débat où le premier consensus n&#x27;est pas toujours le bon, et qu&#x27;il est parfois nécessaire de revenir sur ses positions.</li>
</ul>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>On notera que ces deux études <a href="#sources">[5,6]</a> ont été réalisées dans le cadre d&#x27;une analyse de sentiment général, et non pas spécifique au milieu financier. Leurs résultats démontraient déjà une meilleure analyse qu&#x27;un simple LLM comme <em>BERT</em>.</p></div></div>
<p>Pour tester l&#x27;efficacité de son modèle <strong>HAD</strong>, Franck Xing a utilisé 6 bases de données où ds textes à caractère financier sont annotés en fonction de leur sentiment : <em>FPB</em>, <em>StockSen</em>, <em>CMC</em>, <em>FiQA</em>, <em>SEntFin</em> et <em>FinEntity</em>. Il a comparé les performa,nces de son modèle avec d&#x27;autres méta-modèles de référence, tout en faisant varier la t&#x27;echnologie de LLM employée (<em>BLOOMZ</em>, <em>LlaMa3</em> ou <em>GPT-1</em>).</p>
<div id="had_perf"><p><img decoding="async" loading="lazy" alt="HAD" src="/sentiment_analysis/assets/images/had_perf-c52ed70c932f8d32beb6221f21092cfc.png" width="1243" height="763" class="img_ev3q"></p></div>
<figcaption style="text-align:center"><em>Figure 5 : Performance de <strong>HAD</strong> vis-à-vis de modèles de référence <a href="#source">[3]</a></em></figcaption>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Comparaison des performances</div><div class="admonitionContent_BuS1"><p>Comme on peut le voir sur la <a href="#had_perf">Figure 5</a>, le modèle <strong>HAD</strong> obtient des performances globalement meilleurs que les autres méta-modèles de référence (<em>MSV</em>, <em>MD</em> et <em>HSV</em>). Ses performances sont aussi meilleures que celle d&#x27;un dictionnaire de sentiment financier : <em>Loughan McDonald</em> (que l&#x27;on avait vu dans la section précédente).</p><p>Cependant, on peut noter que les performances de <strong>HAD</strong> et des autre méta-modèles restent globalement bien inférieures à celles du modèle <strong>FinBERT</strong> présenté plus haut. Cette différence significative se fait sur le fait que <strong>HAD</strong> est un modèle conversationnel où les agents ne sont liés entre eux que par un simple biais conversationnel : il n&#x27;y a pas d&#x27;apprentissage à proprement parlé, seulement de la réflexion. <strong>FinBERT</strong> au contraire a été fine-tuné pour l&#x27;analyse de sentiment financier et est lui une structure bien plus complexe et profonde, ce qui explique ses performances supérieures.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="sources">Sources<a href="#sources" class="hash-link" aria-label="Direct link to Sources" title="Direct link to Sources">​</a></h2>
<p><a href="https://www.researchgate.net/publication/347947909_A_Sentiment_Analysis_Approach_to_the_Prediction_of_Market_Volatility" target="_blank" rel="noopener noreferrer">[1] Deveikyte J, Geman H, Piccari C and Provetti A (2022) A sentiment analysis approach to the prediction of market volatility. Front. Artif. Intell. 5:836809. doi: 10.3389/frai.2022.836809</a></p>
<p><a href="https://www.ram-ai.com/sites/default/files/2024-04/202404_ramai_financial-sentiment-analysis-with-llm.pdf" target="_blank" rel="noopener noreferrer">[2] Emmanuel Hauptmann, Valentin Betrix, Nicolas Jamet, Tian Guo, Louis-Alexandre Piquet (2024), Financial Sentiment Analysis with Large Language Models: An Introductory &amp; Comparative Study on News Flow</a></p>
<p><a href="https://doi.org/10.1145/3688399" target="_blank" rel="noopener noreferrer">[3] Frank Xing. 2025. Designing Heterogeneous LLM Agents for Financial Sentiment Analysis. ACM Trans. Manag. Inform. Syst. 16, 1, Article 5 (February 2025), 24 pages.</a></p>
<p><a href="#">[4]</a> Marvin Minsky, The Society of Mind, New York, Simon &amp; Schuster, 1986 (ISBN 0-671-60740-5)</p>
<p><a href="https://doi.org/10.48550/ARXIV.2305.14325" target="_blank" rel="noopener noreferrer">[5] Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. 2024. Improving factuality and reasoning in language models through multiagent debate. In Proceedings of ICML’24.</a></p>
<p><a href="https://doi.org/10.48550/ARXIV.2311.01876" target="_blank" rel="noopener noreferrer">[5] Xiaofei Sun, Xiaoya Li, Shengyu Zhang, Shuhe Wang, Fei Wu, Jiwei Li, Tianwei Zhang, and Guoyin Wang. 2023. Sentiment Analysis through LLM Negotiations</a></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/Anto-nain/sentiment_analysis/edit/main/website/docs/evolution_techno/nlp.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/sentiment_analysis/evolution_techno/dict_senti"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Les premières technologies</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/sentiment_analysis/next"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Et après ?</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#le-finetuning-des-llms-pour-le-rendement-anticipé-dactions" class="table-of-contents__link toc-highlight">Le finetuning des LLMs pour le rendement anticipé d&#39;actions</a></li><li><a href="#les-méta-modèles" class="table-of-contents__link toc-highlight">Les Méta-modèles</a></li><li><a href="#sources" class="table-of-contents__link toc-highlight">Sources</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/sentiment_analysis/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/sentiment_analysis/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/Anto-nain/sentiment_analysis" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>