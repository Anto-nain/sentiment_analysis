"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[96],{2153:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/finbert-7401d575fe89c52e70feee7701045d65.png"},2448:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/had_perf-c52ed70c932f8d32beb6221f21092cfc.png"},4860:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/had_comp-3c0e12a37a6db021b25581144c7238fb.png"},5060:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/bert_embedding-8759513246e46f8e80f5930ff68fcab5.png"},6626:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/bert_perf-842002ccb70ac8cac3e7ae6a33d701c0.png"},7338:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>m,frontMatter:()=>a,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"evolution_techno/nlp_senti","title":"Les LLMs : une nouvelle fa\xe7on d\'analyser les sentiments","description":"Depuis 2018, les LLMs (Large Language Models) ont r\xe9volutionn\xe9 le domaine du traitement automatique du langage naturel (NLP). Ces mod\xe8les, bas\xe9s sur des r\xe9seaux de neurones, sont capables de g\xe9n\xe9rer ou comprendre du texte de mani\xe8re autonome, en fonction d\'une t\xe2che donn\xe9e. Ces nouvelles structures de traitement de texte ne se contentent plus de reconna\xeetre des mots comme le feraient les dictionnaires, mais sont capables de comprendre le sens des phrases \xe0 des niveaux de profondeur parfois plus importants que les humains.","source":"@site/docs/evolution_techno/nlp.md","sourceDirName":"evolution_techno","slug":"/evolution_techno/nlp_senti","permalink":"/sentiment_analysis/evolution_techno/nlp_senti","draft":false,"unlisted":false,"editUrl":"https://github.com/Anto-nain/sentiment_analysis/edit/main/website/docs/evolution_techno/nlp.md","tags":[],"version":"current","frontMatter":{"id":"nlp_senti","sidebar_label":"Les LLMs"},"sidebar":"tutorialSidebar","previous":{"title":"Les premi\xe8res technologies","permalink":"/sentiment_analysis/evolution_techno/dict_senti"},"next":{"title":"Et apr\xe8s ?","permalink":"/sentiment_analysis/next"}}');var r=s(4848),t=s(8453);const a={id:"nlp_senti",sidebar_label:"Les LLMs"},l="Les LLMs : une nouvelle fa\xe7on d'analyser les sentiments",d={},o=[{value:"Le finetuning des LLMs pour le rendement anticip\xe9 d&#39;actions",id:"le-finetuning-des-llms-pour-le-rendement-anticip\xe9-dactions",level:2},{value:"Les M\xe9ta-mod\xe8les",id:"les-m\xe9ta-mod\xe8les",level:2},{value:"Sources",id:"sources",level:2}];function c(e){const n={a:"a",admonition:"admonition",annotation:"annotation",em:"em",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",math:"math",mdxAdmonitionTitle:"mdxAdmonitionTitle",mi:"mi",mo:"mo",mrow:"mrow",ol:"ol",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"les-llms--une-nouvelle-fa\xe7on-danalyser-les-sentiments",children:"Les LLMs : une nouvelle fa\xe7on d'analyser les sentiments"})}),"\n",(0,r.jsx)(n.p,{children:"Depuis 2018, les LLMs (Large Language Models) ont r\xe9volutionn\xe9 le domaine du traitement automatique du langage naturel (NLP). Ces mod\xe8les, bas\xe9s sur des r\xe9seaux de neurones, sont capables de g\xe9n\xe9rer ou comprendre du texte de mani\xe8re autonome, en fonction d'une t\xe2che donn\xe9e. Ces nouvelles structures de traitement de texte ne se contentent plus de reconna\xeetre des mots comme le feraient les dictionnaires, mais sont capables de comprendre le sens des phrases \xe0 des niveaux de profondeur parfois plus importants que les humains."}),"\n",(0,r.jsx)(n.p,{children:"Il s'agira dans cette section de comprendre comment ces mod\xe8les ont permis une avanc\xe9e majeure dans le domaine de l'analyse de sentiment, et comment ils ont des applications concr\xe8tes dans le milieu financier."}),"\n",(0,r.jsx)(n.h2,{id:"le-finetuning-des-llms-pour-le-rendement-anticip\xe9-dactions",children:"Le finetuning des LLMs pour le rendement anticip\xe9 d'actions"}),"\n",(0,r.jsxs)(n.p,{children:["Les premiers LLMs sont apparus en 2018, avec le mod\xe8le ",(0,r.jsx)(n.em,{children:"GPT-1"})," (Generative Pre-trained Transformer). Peu apr\xe8s est arriv\xe9 le premier mod\xe8le open source de google : ",(0,r.jsx)(n.em,{children:"BERT"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.em,{children:"BERT"})," pour ",(0,r.jsx)(n.em,{children:"Bidirectional Encoder Representations from Transformers"})," se distingue du mod\xe8le ",(0,r.jsx)(n.em,{children:"GPT"})," par sa capacit\xe9 \xe0 prendre le contexte pr\xe9c\xe9dent et suivant d'un mot, afin de mieux en comprendre le sens. Dans le papier de recherche de ce mod\xe8le, les auteurs pr\xe9sentent une structure de r\xe9seau de neurone de type ",(0,r.jsx)(n.em,{children:"transformer"})," ",(0,r.jsx)(n.a,{href:"#sources",children:"[1]"}),". La structure de ce r\xe9seau est bas\xe9e sur un assemblage de couches d'encodeurs de transformers qui poss\xe8dent un m\xe9canisme de ",(0,r.jsx)(n.em,{children:"multi-head self-attention"})," et de ",(0,r.jsx)(n.em,{children:"feed-forward neural network"}),". C'est ce qui permet \xe0 ",(0,r.jsx)(n.em,{children:"BERT"})," de r\xe9aliser l'",(0,r.jsx)(n.em,{children:"embedding"})," des inputs textuels."]}),"\n",(0,r.jsxs)(n.admonition,{title:"Embedding",type:"info",children:[(0,r.jsxs)(n.p,{children:["L'",(0,r.jsx)(n.em,{children:"embedding"})," est une technique de traitement de texte qui consiste \xe0 repr\xe9senter les mots ou phrases sous forme de vecteurs. L'objectif est de conserver les relations s\xe9mantiques entre ces derniers, et de les repr\xe9senter dans un espace vectoriel. Ainsi, on peut r\xe9aliser des op\xe9rations math\xe9matiques sur ces vecteurs pour obtenir des informations sur les mots ou phrases qu'ils repr\xe9sentent. Par exemple :"]}),(0,r.jsx)(n.span,{className:"katex-display",children:(0,r.jsxs)(n.span,{className:"katex",children:[(0,r.jsx)(n.span,{className:"katex-mathml",children:(0,r.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,r.jsxs)(n.semantics,{children:[(0,r.jsxs)(n.mrow,{children:[(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"m"}),(0,r.jsx)(n.mi,{children:"b"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"d"}),(0,r.jsx)(n.mi,{children:"d"}),(0,r.jsx)(n.mi,{children:"i"}),(0,r.jsx)(n.mi,{children:"n"}),(0,r.jsx)(n.mi,{children:"g"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"("}),(0,r.jsx)(n.mi,{mathvariant:"normal",children:'"'}),(0,r.jsx)(n.mi,{children:"r"}),(0,r.jsx)(n.mi,{children:"o"}),(0,r.jsx)(n.mi,{children:"i"}),(0,r.jsx)(n.mi,{mathvariant:"normal",children:'"'}),(0,r.jsx)(n.mo,{stretchy:"false",children:")"}),(0,r.jsx)(n.mo,{children:"\u2212"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"m"}),(0,r.jsx)(n.mi,{children:"b"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"d"}),(0,r.jsx)(n.mi,{children:"d"}),(0,r.jsx)(n.mi,{children:"i"}),(0,r.jsx)(n.mi,{children:"n"}),(0,r.jsx)(n.mi,{children:"g"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"("}),(0,r.jsx)(n.mi,{mathvariant:"normal",children:'"'}),(0,r.jsx)(n.mi,{children:"h"}),(0,r.jsx)(n.mi,{children:"o"}),(0,r.jsx)(n.mi,{children:"m"}),(0,r.jsx)(n.mi,{children:"m"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{mathvariant:"normal",children:'"'}),(0,r.jsx)(n.mo,{stretchy:"false",children:")"}),(0,r.jsx)(n.mo,{children:"+"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"m"}),(0,r.jsx)(n.mi,{children:"b"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"d"}),(0,r.jsx)(n.mi,{children:"d"}),(0,r.jsx)(n.mi,{children:"i"}),(0,r.jsx)(n.mi,{children:"n"}),(0,r.jsx)(n.mi,{children:"g"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"("}),(0,r.jsx)(n.mi,{mathvariant:"normal",children:'"'}),(0,r.jsx)(n.mi,{children:"f"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"m"}),(0,r.jsx)(n.mi,{children:"m"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{mathvariant:"normal",children:'"'}),(0,r.jsx)(n.mo,{stretchy:"false",children:")"}),(0,r.jsx)(n.mo,{children:"\u2248"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"m"}),(0,r.jsx)(n.mi,{children:"b"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"d"}),(0,r.jsx)(n.mi,{children:"d"}),(0,r.jsx)(n.mi,{children:"i"}),(0,r.jsx)(n.mi,{children:"n"}),(0,r.jsx)(n.mi,{children:"g"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"("}),(0,r.jsx)(n.mi,{mathvariant:"normal",children:'"'}),(0,r.jsx)(n.mi,{children:"r"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"i"}),(0,r.jsx)(n.mi,{children:"n"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{mathvariant:"normal",children:'"'}),(0,r.jsx)(n.mo,{stretchy:"false",children:")"})]}),(0,r.jsx)(n.annotation,{encoding:"application/x-tex",children:'embedding("roi") - embedding("homme") + embedding("femme") \\approx embedding("reine")'})]})})}),(0,r.jsxs)(n.span,{className:"katex-html","aria-hidden":"true",children:[(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"mb"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"dd"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"in"}),(0,r.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"g"}),(0,r.jsx)(n.span,{className:"mopen",children:"("}),(0,r.jsx)(n.span,{className:"mord",children:'"'}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"ro"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"i"}),(0,r.jsx)(n.span,{className:"mord",children:'"'}),(0,r.jsx)(n.span,{className:"mclose",children:")"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,r.jsx)(n.span,{className:"mbin",children:"\u2212"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"mb"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"dd"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"in"}),(0,r.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"g"}),(0,r.jsx)(n.span,{className:"mopen",children:"("}),(0,r.jsx)(n.span,{className:"mord",children:'"'}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"h"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"o"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"mm"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord",children:'"'}),(0,r.jsx)(n.span,{className:"mclose",children:")"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,r.jsx)(n.span,{className:"mbin",children:"+"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"mb"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"dd"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"in"}),(0,r.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"g"}),(0,r.jsx)(n.span,{className:"mopen",children:"("}),(0,r.jsx)(n.span,{className:"mord",children:'"'}),(0,r.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.10764em"},children:"f"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"mm"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord",children:'"'}),(0,r.jsx)(n.span,{className:"mclose",children:")"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,r.jsx)(n.span,{className:"mrel",children:"\u2248"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"mb"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"dd"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"in"}),(0,r.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"g"}),(0,r.jsx)(n.span,{className:"mopen",children:"("}),(0,r.jsx)(n.span,{className:"mord",children:'"'}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"re"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"in"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord",children:'"'}),(0,r.jsx)(n.span,{className:"mclose",children:")"})]})]})]})})]}),"\n",(0,r.jsxs)(n.p,{children:["\xc0 l'inverse des techniques de ",(0,r.jsx)(n.em,{children:"word-embedding"})," classiques telles que ",(0,r.jsx)(n.em,{children:"Word2Vec"})," ou ",(0,r.jsx)(n.em,{children:"GloVe"}),", ",(0,r.jsx)(n.em,{children:"BERT"})," est capable de prendre en compte le contexte global du texte pour r\xe9aliser l'",(0,r.jsx)(n.em,{children:"embedding"})," des mots. C'est ce qui lui donne une compr\xe9hension plus fine du sens des mots et des phrases. ",(0,r.jsx)(n.em,{children:"BERT"})," va donc r\xe9aliser 3 ",(0,r.jsx)(n.em,{children:"embeddings"})," diff\xe9rents pour chaque mot (voir ",(0,r.jsx)(n.a,{href:"#bert-embedding",children:"Figure 1"}),") :"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"l'embedding du mot lui-m\xeame"}),"\n",(0,r.jsx)(n.li,{children:"l'embedding de la position du mot"}),"\n",(0,r.jsx)(n.li,{children:"l'embedding de la position de la phrase dans le texte"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Ce sont ces 2 derniers ",(0,r.jsx)(n.em,{children:"embeddings"})," qui permettent \xe0 ",(0,r.jsx)(n.em,{children:"BERT"})," de comprendre le contexte global du texte et de d\xe9tecter ses structures ",(0,r.jsx)(n.em,{children:"questions/r\xe9ponses"}),"."]}),"\n",(0,r.jsx)("div",{id:"bert-embedding",children:(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"BERT embedding",src:s(5060).A+"",width:"1633",height:"508"})})}),"\n",(0,r.jsx)("figcaption",{style:{textAlign:"center"},children:(0,r.jsxs)("em",{children:["Figure 1 : Embedding des inputs dans le mod\xe8le BERT ",(0,r.jsx)(n.a,{href:"#ref1",children:"[1]"})]})}),"\n",(0,r.jsxs)(n.p,{children:["L'entrainement d'un mod\xe8le de ",(0,r.jsx)(n.em,{children:"LLM"})," comme ",(0,r.jsx)(n.em,{children:"BERT"})," se fait en deux \xe9tapes :"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"1/ Pr\xe9-entrainement"})}),"\n",(0,r.jsxs)(n.p,{children:["Le mod\xe8le apprend \xe0 r\xe9aliser les 3 ",(0,r.jsx)(n.em,{children:"embeddings"})," des mots d'un texte. Pour cela, il est entra\xeen\xe9 sur deux t\xe2ches principales :"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"Masked Language Model"})," : 15% des mots du texte sont masqu\xe9s, et le mod\xe8le doit apprendre \xe0 les retrouver en fonction du contexte."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"Next Sentence Prediction"})," : on donne deux phrases, A et B au mod\xe8le tel que B est la phrase suivante de A dans 50% des cas. Le mod\xe8le doit alors apprendre \xe0 d\xe9terminer si B est bien la phrase suivante de A."]}),"\n"]}),"\n",(0,r.jsx)(n.admonition,{title:"Objectif du pr\xe9-entrainement",type:"tip",children:(0,r.jsxs)(n.p,{children:["Gr\xe2ce au pr\xe9-entrainement, ",(0,r.jsx)(n.em,{children:"BERT"})," apprend deux notions fondamentales pour sa compr\xe9hension du langage : La coh\xe9rence ",(0,r.jsx)(n.strong,{children:"contextuelle"})," et ",(0,r.jsx)(n.strong,{children:"s\xe9mantique"})," du langage."]})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"2/ Fine-tuning"})}),"\n",(0,r.jsxs)(n.p,{children:["Une fois pr\xe9-entrain\xe9, on peut r\xe9-entrainer ",(0,r.jsx)(n.em,{children:"BERT"})," pour qu'il r\xe9alise une t\xe2che bien pr\xe9cise. Ayant au pr\xe9alable acquis un compr\xe9hension du langage, il peut maintenant apprendre \xe0 r\xe9aliser une t\xe2che plus complexe sur les donn\xe9es textuelles. On peut notamment lui apprendre \xe0 g\xe9n\xe9rer du texte pour r\xe9pondre \xe0 une question ou \xe0 r\xe9aliser une classification de texte ; pour d\xe9tecter des spams par exemple."]}),"\n",(0,r.jsxs)(n.p,{children:["Dans le contexte de l'analyse de sentiment, on peut utiliser le mod\xe8le pr\xe9-entrain\xe9 de ",(0,r.jsx)(n.em,{children:"BERT"})," pour r\xe9aliser une classification des textes en fonction de leur sentiment. C'est notamment ce qu'on r\xe9alis\xe9 l'\xe9quipe ",(0,r.jsx)(n.em,{children:"Systematic Equity"})," chez ",(0,r.jsx)(n.em,{children:"RAM AI"})," ",(0,r.jsx)(n.a,{href:"#sources",children:"[2]"}),"."]}),"\n",(0,r.jsx)(n.admonition,{title:"L'importance de la donn\xe9e",type:"warning",children:(0,r.jsxs)(n.p,{children:["Le pr\xe9-entrainement d'un ",(0,r.jsx)(n.em,{children:"LLM"})," comme ",(0,r.jsx)(n.em,{children:"BERT"})," n\xe9cessite une grande quantit\xe9 de donn\xe9es textuelles de bonne qualit\xe9. Pour ce faire, on utilise souvent des corpus de textes libres, comme ",(0,r.jsx)(n.em,{children:"Wikipedia"})," ou ",(0,r.jsx)(n.em,{children:"Common Crawl"}),". Cependant, ces donn\xe9es ne sont pas toujours adapt\xe9es \xe0 la t\xe2che finale que l'on souhaite r\xe9aliser. Dans le cadre financier, de nombreux termes techniques ou sp\xe9cifiques peuvent ne pas \xeatre pr\xe9sents dans ces corpus, ou tout du moins pas en suffisamment grande quantit\xe9 pour que le mod\xe8le comprenne pleinement leur sens."]})}),"\n",(0,r.jsxs)(n.p,{children:["Dans ce contexte financier d'analyse de sentiment, l'\xe9quipe de ",(0,r.jsx)(n.em,{children:"RAM AI"})," a donc d'abord r\xe9alis\xe9 un fine-tuning de ",(0,r.jsx)(n.em,{children:"BERT"})," sur un corpus de donn\xe9es financi\xe8res avec des \xe9tiquettes de sentiments. Ce mod\xe8le de langage renomm\xe9 ",(0,r.jsx)(n.strong,{children:"FinBERT"})," est donc maintenant capable de comprendre le langage en g\xe9n\xe9ral et tout particuli\xe8rement le langage financier et les sentiments associ\xe9s \xe0 ce dernier (voir ",(0,r.jsx)(n.a,{href:"#finbert",children:"Figure 2"}),")."]}),"\n",(0,r.jsx)("div",{id:"finbert",children:(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"FinBERT",src:s(2153).A+"",width:"1212",height:"457"})})}),"\n",(0,r.jsx)("figcaption",{style:{textAlign:"center"},children:(0,r.jsxs)("em",{children:["Figure 2 : Fine-tuning de BERT pour l'analyse de sentiment financier ",(0,r.jsx)(n.a,{href:"#sources",children:"[2]"})]})}),"\n",(0,r.jsxs)(n.p,{children:["\xc0 partir de ",(0,r.jsx)(n.strong,{children:"FinBERT"}),", l'\xe9quipe de ",(0,r.jsx)(n.em,{children:"RAM AI"})," a aussi mis au point une version ",(0,r.jsx)(n.em,{children:"Ditangled"})," pour d\xe9corr\xe9ler les m\xe9canismes du mod\xe8le ",(0,r.jsx)(n.em,{children:"BERT"})," (notamment sur la dimension la dimension des embeddings et sur le m\xe9canisme d'attention) : ",(0,r.jsx)(n.strong,{children:"FinDeBERTa"}),". D'un point de vue des performances, ils ont utilis\xe9s ces mod\xe8les pour pr\xe9dire le sentiment des march\xe9s financiers sur des donn\xe9es de nouvelles financi\xe8res. Leur objectif \xe9tait de simuler un investissement dans des actions du march\xe9 afin d'am\xe9liorer leur ",(0,r.jsx)(n.em,{children:"rendement"})," (d\xe9fini sur la page pr\xe9c\xe9dente). En comparant les performances de ",(0,r.jsx)(n.strong,{children:"FinBERT"})," et ",(0,r.jsx)(n.strong,{children:"FinDeBERTa"})," avec ",(0,r.jsx)(n.strong,{children:"FinVADER"})," (un dictionnaire de sentiment ax\xe9 sur la finance vu sur la page pr\xe9c\xe9dente), ils ont obtenus les r\xe9sultats de la ",(0,r.jsx)(n.a,{href:"#finbert-perf",children:"Figure 3"}),"."]}),"\n",(0,r.jsx)("div",{id:"finbert-perf",children:(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Performances de FinBERT et FinDeBERTa",src:s(6626).A+"",width:"963",height:"712"})})}),"\n",(0,r.jsx)("figcaption",{style:{textAlign:"center"},children:(0,r.jsxs)("em",{children:["Figure 3 : Performances de FinBERT et FinDeBERTa compar\xe9es \xe0 FinVADER ",(0,r.jsx)(n.a,{href:"#sources",children:"[2]"})]})}),"\n",(0,r.jsx)(n.admonition,{title:"Ce qu'il faut retenir",type:"tip",children:(0,r.jsxs)(n.p,{children:["Dans le cadre d'une simulation d'investissement sur le march\xe9 des actions, les mod\xe8les de ",(0,r.jsx)(n.em,{children:"LLM"})," affin\xe9s pour l'analyse de sentiment financier produisent des r\xe9sultats significativement meilleurs que les dictionnaires de sentiment classiques. Cela est du \xe0 leur compr\xe9hension plus fine et enti\xe8re du language financier.\r\nEn moyenne, on peut noter une am\xe9lioration 3 \xe0 4 fois sup\xe9rieure \xe0 l'utilisation d'un dictionnaire de sentiment (m\xeame sp\xe9cifique \xe0 la finance)."]})}),"\n",(0,r.jsx)(n.h2,{id:"les-m\xe9ta-mod\xe8les",children:"Les M\xe9ta-mod\xe8les"}),"\n",(0,r.jsxs)(n.p,{children:["Une des avanc\xe9e les plus surprenante concernant l'utilisation des ",(0,r.jsx)(n.em,{children:"LLMs"})," est leur transformation en agent conversationnel. Ces nouveaux syst\xe8mes intelligents sont au coeur de la recherche en IA pour l'analyse de sentiment, notamment dans le domaine financier."]}),"\n",(0,r.jsxs)(n.p,{children:["Lorsque l'on travaille dans le milieu financier, ou plus g\xe9n\xe9ralement dans un domaine critique, il est important de pouvoir d\xe9tailler rigouresement le cheminement d'un pens\xe9e. Les IAs g\xe9n\xe9ratives, comme ",(0,r.jsx)(n.em,{children:"FinBERT"})," de la section pr\xe9c\xe9dent ne le font naturellement pas. C'est pourquoi il est souvent n\xe9cessaire de leur apprendre \xe0 raisonner de fa\xe7on logique et humaine. Pour ce faire, il existe de nombreuses m\xe9thodes, qui permettent en plus d'am\xe9liorer la pr\xe9cision et la qualit\xe9 des r\xe9ponses de ces agents, dont notamment les ",(0,r.jsx)(n.em,{children:"Chain of Thought"}),", ",(0,r.jsx)(n.em,{children:"Tree of Thought"})," ou encore des m\xe9canismes d'",(0,r.jsx)(n.em,{children:"auto-v\xe9rification de la coh\xe9rence"}),"."]}),"\n",(0,r.jsxs)(n.admonition,{type:"info",children:[(0,r.jsxs)(n.mdxAdmonitionTitle,{children:[(0,r.jsx)(n.em,{children:"Chain of Thought"})," et ",(0,r.jsx)(n.em,{children:"Tree of Thought"})]}),(0,r.jsxs)(n.p,{children:["Les ",(0,r.jsx)(n.em,{children:"Chain of Thought (CoT)"})," et ",(0,r.jsx)(n.em,{children:"Tree of Thoughts (ToT)"})," sont des techniques d\u2019am\xe9lioration du raisonnement pour les mod\xe8les de langage. ",(0,r.jsx)(n.em,{children:"CoT"})," guide le mod\xe8le \xe0 d\xe9composer une t\xe2che en plusieurs \xe9tapes explicites, am\xe9liorant ainsi la coh\xe9rence des r\xe9ponses. ",(0,r.jsx)(n.em,{children:"ToT"}),", quant \xe0 lui, \xe9tend cette id\xe9e en explorant plusieurs chemins de raisonnement sous forme d\u2019un arbre, permettant au mod\xe8le d\u2019\xe9valuer diff\xe9rentes solutions avant de choisir la meilleure. Alors que ",(0,r.jsx)(n.em,{children:"CoT"})," suit un raisonnement lin\xe9aire, ",(0,r.jsx)(n.em,{children:"ToT"})," est plus puissant pour les t\xe2ches complexes n\xe9cessitant une exploration et une prise de d\xe9cision optimales."]})]}),"\n",(0,r.jsxs)(n.p,{children:["Ces mod\xe8les, performants pour analyser les sentiments dans de nombreux domaines, ont pourtant certaines limitations dans leur r\xe9flexion. Ils ne sont en effet, pas capables de proposer des raisonnements intellectuels spontan\xe9s ; c'est-&-dire autres que dans le cadre qui leur a \xe9t\xe9 appris (",(0,r.jsx)(n.em,{children:"CoT"}),", ",(0,r.jsx)(n.em,{children:"ToT"}),", ...).Dans l'article ",(0,r.jsx)(n.em,{children:"Designing Heterogeneous LLM Agents for Financial Sentiment Analysis"})," ",(0,r.jsx)(n.a,{href:"#sources",children:"[3]"})," Franck Xing d\xe9peint l'utilisation de diff\xe9rents m\xe9ta-mod\xe8les pour palier ces limitations."]}),"\n",(0,r.jsx)(n.admonition,{title:"Les m\xe9ta-mod\xe8les",type:"info",children:(0,r.jsx)(n.p,{children:"Un m\xe9ta-mod\xe8le est une structure conceptuelle qui d\xe9finit les r\xe8gles et les relations r\xe9gissant un ensemble de mod\xe8les sp\xe9cifiques. Il sert de cadre g\xe9n\xe9ral permettant d\u2019organiser, d\u2019interconnecter et d\u2019adapter diff\xe9rents mod\xe8les selon les besoins d\u2019un domaine donn\xe9. Dans le contexte des agents conversationnels, un m\xe9ta-mod\xe8le peut orchestrer plusieurs sous-mod\xe8les sp\xe9cialis\xe9s (compr\xe9hension, g\xe9n\xe9ration, m\xe9moire contextuelle, raisonnement, etc.), afin de produire agent plus flexible, capable de mieux structurer ses r\xe9ponses et d\u2019adapter son comportement aux interactions."})}),"\n",(0,r.jsx)(n.p,{children:"Dans cet article, Franck Xing propose un m\xe9ta-mod\xe8le inspir\xe9 de la th\xe9orie de l'esprit de Marvin Minsky."}),"\n",(0,r.jsxs)(n.admonition,{type:"note",children:[(0,r.jsx)(n.mdxAdmonitionTitle,{children:(0,r.jsx)(n.em,{children:"The Society of Mind - Marvin Minsky"})}),(0,r.jsxs)(n.p,{children:["Dans son livre intitul\xe9 ",(0,r.jsx)(n.em,{children:"The Society of Mind"})," ",(0,r.jsx)(n.a,{href:"#sources",children:"[4]"}),", Marvin Minsky pr\xe9sente une approche th\xe9orique qui propose que l'intelligence humaine \xe9merge de l'interaction de nombreux agents cognitifs ou modules sp\xe9cialis\xe9s dans le cerveau."]})]}),"\n",(0,r.jsxs)(n.p,{children:["En suivant cette th\xe9orie, Franck Xing propose un m\xe9ta-mod\xe8le d'agents conversationnels dont les conversations cherchent \xe0 am\xe9liorer la qualit\xe9 de la r\xe9flexion de l'agent. Ce mod\xe8le, le ",(0,r.jsx)(n.strong,{children:"HAD"})," pour ",(0,r.jsx)(n.strong,{children:"Heterogeneous multi-Angent Discussion"}),", est compos\xe9 de 7 types d'agents ; 5 d'entre-eux sont des agents linguistiques et 2 sont des agents financiers :"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Agents linguistiques"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"A1 - agent mood"})," : d\xe9tecte les moods irr\xe9alistes, c'est-\xe0-dire des expressions qui indiquent des conditions hypoth\xe9tiques ou improbables. Par exemple : \"Si les conditions \xe9conomiques s'am\xe9liorent alors...\""]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"A2 - agent rh\xe9torique"})," : identifie les rh\xe9toriques, comme le sarcasme ou les assertions n\xe9gatives."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"A3 - agent d\xe9pendance"}),' : se concentre sur le sentiment de l\'orateur, et non sur celui d\'un tiers. Par exemple : "Nous sommes optimistes" (focus sur l\'orateur) et "Les analystes sont optimistes" (focus sur un tiers).']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"A4 - agent aspect"})," : se concentre sur le sujet principal (par exemple, une action ou un produit) et non sur des aspects secondaires."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"A5 - agent r\xe9f\xe9rence"})," : d\xe9tecte les r\xe9f\xe9rences temporelles, les prix et autres faits non exprim\xe9s."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Agents financiers"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"A6 - agent institutionnel"})," : analyse le texte du point de vue d'un investisseur institutionnel, en se concentrant sur les effets fondamentaux \xe0 long terme"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"A7 - agent individuel"})," : analyse le texte du point de vue d'un investisseur individuel, en se concentrant sur les changements de prix et les indicateurs techniques."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Cette structure de m\xe9ta-mod\xe8le avec diff\xe9rents types d'agents tous focus sur des aspects diff\xe9rents de l'analyse du texte se distingue par sa complexit\xe9 des autres m\xe9ta-mod\xe8les existants. Cette structure plus complexe mimique en effet plus fid\xe8lement le fonctionnement du cerveau humain, ou \xe0 fortiori, d'un analyste financier ou de son \xe9quipe : chacun se concentrant sur un aspect particulier de l'analyse."}),"\n",(0,r.jsx)("div",{id:"had",children:(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"HAD",src:s(4860).A+"",width:"1567",height:"727"})})}),"\n",(0,r.jsx)("figcaption",{style:{textAlign:"center"},children:(0,r.jsxs)("em",{children:["Figure 4 : Diff\xe9rentes structures de m\xe9ta-mod\xe8les en multi-agent, (a) ",(0,r.jsx)(n.strong,{children:"homogeneous multi-agent debate"}),", (b) ",(0,r.jsx)(n.strong,{children:"multi-role multi-agent negotiation"}),", (c) ",(0,r.jsx)(n.strong,{children:"heterogeneous multi-agent discussion (HAD)"})," ",(0,r.jsx)(n.a,{href:"#source",children:"[3]"})]})}),"\n",(0,r.jsxs)(n.p,{children:["Dans la ",(0,r.jsx)(n.a,{href:"#had",children:"Figure 4"}),", on peut voir deux autres structures de m\xe9ta-mod\xe8les plus simples que le ",(0,r.jsx)(n.strong,{children:"HAD"})," (c) :"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["(a) ",(0,r.jsx)(n.strong,{children:"Homogeneous multi-agent debate"})," : cette structure pr\xe9sent\xe9e par les recherches de Yilun DU et al. ",(0,r.jsx)(n.a,{href:"#sources",children:"[5]"})," propose de lier des nombreux agents identiques au sein d'un m\xeame mod\xe8le. Toujours en s'appuyant sur la th\xe9orie de Minsky ",(0,r.jsx)(n.a,{href:"#sources",children:"[4]"}),", ils ont fait d\xe9batre leurs agents pour analyser sentimentalement un texte."]}),"\n",(0,r.jsxs)(n.li,{children:["(b) ",(0,r.jsx)(n.strong,{children:"Multi-role multi-agent negotiation"})," : cette structure pr\xe9sent\xe9e par les recherches de Xiaofei SUN et al. ",(0,r.jsx)(n.a,{href:"#sources",children:"[6]"}),", fait intervenir des agents dans une n\xe9gotiation chacun ayant un r\xf4le diff\xe9rent. Cette structure, plus proche du ",(0,r.jsx)(n.strong,{children:"HAD"}),", se distingue par le fait que les agents ont le m\xeame type d'analyse ; seul leur r\xf4le dans le d\xe9bat diff\xe8re (n\xe9gociateur, observateur, ...). Suite aux n\xe9gociations, le consensus atteint est syt\xe9matiquement remis en question. Cela mimique le d\xe9roul\xe9 d'un vrai d\xe9bat o\xf9 le premier consensus n'est pas toujours le bon, et qu'il est parfois n\xe9cessaire de revenir sur ses positions."]}),"\n"]}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["On notera que ces deux \xe9tudes ",(0,r.jsx)(n.a,{href:"#sources",children:"[5,6]"})," ont \xe9t\xe9 r\xe9alis\xe9es dans le cadre d'une analyse de sentiment g\xe9n\xe9ral, et non pas sp\xe9cifique au milieu financier. Leurs r\xe9sultats d\xe9montraient d\xe9j\xe0 une meilleure analyse qu'un simple LLM comme ",(0,r.jsx)(n.em,{children:"BERT"}),"."]})}),"\n",(0,r.jsxs)(n.p,{children:["Pour tester l'efficacit\xe9 de son mod\xe8le ",(0,r.jsx)(n.strong,{children:"HAD"}),", Franck Xing a utilis\xe9 6 bases de donn\xe9es o\xf9 ds textes \xe0 caract\xe8re financier sont annot\xe9s en fonction de leur sentiment : ",(0,r.jsx)(n.em,{children:"FPB"}),", ",(0,r.jsx)(n.em,{children:"StockSen"}),", ",(0,r.jsx)(n.em,{children:"CMC"}),", ",(0,r.jsx)(n.em,{children:"FiQA"}),", ",(0,r.jsx)(n.em,{children:"SEntFin"})," et ",(0,r.jsx)(n.em,{children:"FinEntity"}),". Il a compar\xe9 les performa,nces de son mod\xe8le avec d'autres m\xe9ta-mod\xe8les de r\xe9f\xe9rence, tout en faisant varier la t'echnologie de LLM employ\xe9e (",(0,r.jsx)(n.em,{children:"BLOOMZ"}),", ",(0,r.jsx)(n.em,{children:"LlaMa3"})," ou ",(0,r.jsx)(n.em,{children:"GPT-1"}),")."]}),"\n",(0,r.jsx)("div",{id:"had_perf",children:(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"HAD",src:s(2448).A+"",width:"1243",height:"763"})})}),"\n",(0,r.jsx)("figcaption",{style:{textAlign:"center"},children:(0,r.jsxs)("em",{children:["Figure 5 : Performance de ",(0,r.jsx)(n.strong,{children:"HAD"})," vis-\xe0-vis de mod\xe8les de r\xe9f\xe9rence ",(0,r.jsx)(n.a,{href:"#source",children:"[3]"})]})}),"\n",(0,r.jsxs)(n.admonition,{title:"Comparaison des performances",type:"tip",children:[(0,r.jsxs)(n.p,{children:["Comme on peut le voir sur la ",(0,r.jsx)(n.a,{href:"#had_perf",children:"Figure 5"}),", le mod\xe8le ",(0,r.jsx)(n.strong,{children:"HAD"})," obtient des performances globalement meilleurs que les autres m\xe9ta-mod\xe8les de r\xe9f\xe9rence (",(0,r.jsx)(n.em,{children:"MSV"}),", ",(0,r.jsx)(n.em,{children:"MD"})," et ",(0,r.jsx)(n.em,{children:"HSV"}),"). Ses performances sont aussi meilleures que celle d'un dictionnaire de sentiment financier : ",(0,r.jsx)(n.em,{children:"Loughan McDonald"})," (que l'on avait vu dans la section pr\xe9c\xe9dente)."]}),(0,r.jsxs)(n.p,{children:["Cependant, on peut noter que les performances de ",(0,r.jsx)(n.strong,{children:"HAD"})," et des autre m\xe9ta-mod\xe8les restent globalement bien inf\xe9rieures \xe0 celles du mod\xe8le ",(0,r.jsx)(n.strong,{children:"FinBERT"})," pr\xe9sent\xe9 plus haut. Cette diff\xe9rence significative se fait sur le fait que ",(0,r.jsx)(n.strong,{children:"HAD"})," est un mod\xe8le conversationnel o\xf9 les agents ne sont li\xe9s entre eux que par un simple biais conversationnel : il n'y a pas d'apprentissage \xe0 proprement parl\xe9, seulement de la r\xe9flexion. ",(0,r.jsx)(n.strong,{children:"FinBERT"})," au contraire a \xe9t\xe9 fine-tun\xe9 pour l'analyse de sentiment financier et est lui une structure bien plus complexe et profonde, ce qui explique ses performances sup\xe9rieures."]})]}),"\n",(0,r.jsx)(n.h2,{id:"sources",children:"Sources"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://www.researchgate.net/publication/347947909_A_Sentiment_Analysis_Approach_to_the_Prediction_of_Market_Volatility",children:"[1] Deveikyte J, Geman H, Piccari C and Provetti A (2022) A sentiment analysis approach to the prediction of market volatility. Front. Artif. Intell. 5:836809. doi: 10.3389/frai.2022.836809"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://www.ram-ai.com/sites/default/files/2024-04/202404_ramai_financial-sentiment-analysis-with-llm.pdf",children:"[2] Emmanuel Hauptmann, Valentin Betrix, Nicolas Jamet, Tian Guo, Louis-Alexandre Piquet (2024), Financial Sentiment Analysis with Large Language Models: An Introductory & Comparative Study on News Flow"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://doi.org/10.1145/3688399",children:"[3] Frank Xing. 2025. Designing Heterogeneous LLM Agents for Financial Sentiment Analysis. ACM Trans. Manag. Inform. Syst. 16, 1, Article 5 (February 2025), 24 pages."})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"#",children:"[4]"})," Marvin Minsky, The Society of Mind, New York, Simon & Schuster, 1986 (ISBN 0-671-60740-5)"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://doi.org/10.48550/ARXIV.2305.14325",children:"[5] Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. 2024. Improving factuality and reasoning in language models through multiagent debate. In Proceedings of ICML\u201924."})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://doi.org/10.48550/ARXIV.2311.01876",children:"[5] Xiaofei Sun, Xiaoya Li, Shengyu Zhang, Shuhe Wang, Fei Wu, Jiwei Li, Tianwei Zhang, and Guoyin Wang. 2023. Sentiment Analysis through LLM Negotiations"})})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>l});var i=s(6540);const r={},t=i.createContext(r);function a(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);